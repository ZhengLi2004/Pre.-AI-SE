\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\citation{Zhou2024}
\citation{Kenfack2021}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{Li2024}
\citation{Zhou2024}
\citation{Chen2004}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivation of AI in Software Testing}{2}{subsection.1.1}\protected@file@percent }
\citation{Guo2024}
\citation{Kenfack2021}
\citation{Li2018}
\citation{Chib1995}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}AI as a Tool for Testing Traditional Systems}{3}{subsection.1.2}\protected@file@percent }
\citation{Ribeiro2016,Lundberg2017}
\citation{Chen2004}
\@writefile{toc}{\contentsline {section}{\numberline {2}AI-Driven Test Data Generation}{4}{section.2}\protected@file@percent }
\citation{Li2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Data Augmentation for Edge Cases}{5}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Introduction}{5}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Augmentation Framework}{5}{subsubsection.2.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Ablation Study}{5}{subsubsection.2.1.3}\protected@file@percent }
\citation{Lundberg2017}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Three-level data augmentation framework for domain generalization, demonstrating (A) domain mixing via CycleGAN, (B) image transformations with RandAugment, and © feature space interpolation}}{6}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:augmentation_framework}{{1}{6}{Three-level data augmentation framework for domain generalization, demonstrating (A) domain mixing via CycleGAN, (B) image transformations with RandAugment, and © feature space interpolation}{figure.caption.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Performance comparison of augmentation strategies on PACS dataset}}{6}{table.caption.3}\protected@file@percent }
\newlabel{tab:aug_performance}{{1}{6}{Performance comparison of augmentation strategies on PACS dataset}{table.caption.3}{}}
\citation{Kenfack2021}
\citation{Zhou2024}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Theoretical Significance}{7}{subsubsection.2.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.5}Future Improvements}{7}{subsubsection.2.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Generative AI for Synthetic Data}{7}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Advantages of Using Generative AI in Testing}{7}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Advantages of Generative AI in Synthetic Data Generation}}{8}{table.caption.4}\protected@file@percent }
\newlabel{tab:gan-advantages}{{2}{8}{Advantages of Generative AI in Synthetic Data Generation}{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Limitations and Ethical Challenges}{8}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Impact of Biased Generative Data: Tay Chatbot Case Study}}{8}{table.caption.5}\protected@file@percent }
\newlabel{tab:tay-case}{{3}{8}{Impact of Biased Generative Data: Tay Chatbot Case Study}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Bias in Testing: Influence on Model Performance}{8}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Best Practices for Ethical and Fair Use of Generative AI in Testing}{8}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Examples of Bias Impact in Synthetic Testing Scenarios}}{9}{table.caption.6}\protected@file@percent }
\newlabel{tab:bias-impact}{{4}{9}{Examples of Bias Impact in Synthetic Testing Scenarios}{table.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}AI-Powered Test Case Optimization}{9}{section.3}\protected@file@percent }
\newlabel{sec:3}{{3}{9}{AI-Powered Test Case Optimization}{section.3}{}}
\citation{Guo2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Boundary Value Analysis with BCD Optimization}{10}{subsection.3.1}\protected@file@percent }
\citation{Guo2024}
\@writefile{toc}{\contentsline {paragraph}{Algorithm 1: Greedy Descent BCD Optimization}{11}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Algorithm 2: ``Harmless'' Boundary Improvement Strategy}{12}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Algorithm 3: Probabilistic Acceptance (MCMC with Temperature)}{12}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Boundary Distribution for English Exam Grading}{12}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Reinforcement Learning for Test Exploration}{12}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Basic boundary distribution for the English exam grading program: gray indicates invalid inputs ($I_1$), blue indicates fail ($I_3$), orange indicates pass ($I_2$), and black dashed lines show the equivalence partition boundaries.}}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:english_boundary}{{2}{13}{Basic boundary distribution for the English exam grading program: gray indicates invalid inputs ($I_1$), blue indicates fail ($I_3$), orange indicates pass ($I_2$), and black dashed lines show the equivalence partition boundaries}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{Agent-Environment Construction}{13}{section*.17}\protected@file@percent }
\citation{Li2018}
\@writefile{toc}{\contentsline {paragraph}{Dynamic Threshold Design and Case Illustration}{14}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reinforcement Learning Algorithm Example}{15}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Experimental Results and Comparison}{15}{section*.20}\protected@file@percent }
\citation{genprog}
\citation{angelix}
\citation{deeprepair}
\citation{tbar}
\@writefile{toc}{\contentsline {section}{\numberline {4}AI in Automated Testing Frameworks}{16}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Self-Supervised Program Repair (SelfAPR)}{16}{subsection.4.1}\protected@file@percent }
\citation{defects4j}
\citation{selfapr_paper}
\citation{selfapr_paper}
\citation{selfapr_paper}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Overview of SelfAPR: key novel features are the training sample generator and the diagnostic in the input representation.\nonbreakingspace \citep  {selfapr_paper}.}}{18}{figure.caption.21}\protected@file@percent }
\newlabel{fig:APRframework}{{3}{18}{Overview of SelfAPR: key novel features are the training sample generator and the diagnostic in the input representation.~\cite {selfapr_paper}}{figure.caption.21}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Selected Perturbation Rules in SelfAPR}}{18}{table.caption.22}\protected@file@percent }
\newlabel{tab:perturbation_rules}{{5}{18}{Selected Perturbation Rules in SelfAPR}{table.caption.22}{}}
\citation{gzoltar}
\citation{defects4j}
\citation{genprog}
\citation{jgenprog}
\citation{nopol}
\citation{angelix}
\citation{deeprepair}
\citation{tbar}
\citation{recoder}
\citation{cure}
\citation{buglab}
\citation{rewardrepair}
\citation{aprgnn}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Comparison of Repair Performance on Defects4J}}{20}{table.caption.23}\protected@file@percent }
\newlabel{tab:comparison}{{6}{20}{Comparison of Repair Performance on Defects4J}{table.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}AI-Driven CI/CD integration}{20}{subsection.4.2}\protected@file@percent }
\citation{Bifet2007}
\citation{Bifet2007}
\@writefile{toc}{\contentsline {paragraph}{Automated Test Case Generation}{21}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Intelligent Deployment Strategies}{21}{section*.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Jenkins Integration with AI}{21}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Output of the ADWIN algorithm illustrating abrupt concept drift. When the average error changes significantly, ADWIN shrinks the window and triggers model adjustment. Adapted from Bifet and Gavaldà\nonbreakingspace \citep  {Bifet2007}.}}{22}{figure.caption.28}\protected@file@percent }
\newlabel{fig:adwin}{{4}{22}{Output of the ADWIN algorithm illustrating abrupt concept drift. When the average error changes significantly, ADWIN shrinks the window and triggers model adjustment. Adapted from Bifet and Gavaldà~\cite {Bifet2007}}{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}AI-Driven Deployment Strategies}{22}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Cloud-Native Testing Platforms with High Concurrency Handling}{22}{subsubsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Terraform for Resource Management}{23}{subsubsection.4.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5}High Concurrency Testing Practices}{23}{subsubsection.4.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6}Challenges and Solutions}{23}{subsubsection.4.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Challenge 1: Accuracy of AI-Generated Test Cases}{23}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Challenge 2: Cost Control in Cloud Environments}{23}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Challenge 3: Security and Compliance}{23}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.7}Conclusion}{24}{subsubsection.4.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}AI for Defect Prediction and Root-Cause Analysis}{24}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Machine Learning for Bug Localization}{24}{subsection.5.1}\protected@file@percent }
\citation{Li2024}
\citation{Li2024}
\citation{Li2024}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Architecture of a machine learning-based bug localization framework. The system collects predicate information during execution and learns cause-effect chains using statistical models. Adapted from Jiang and Su\nonbreakingspace \citep  {Li2024}.}}{25}{figure.caption.32}\protected@file@percent }
\newlabel{fig:framework}{{5}{25}{Architecture of a machine learning-based bug localization framework. The system collects predicate information during execution and learns cause-effect chains using statistical models. Adapted from Jiang and Su~\cite {Li2024}}{figure.caption.32}{}}
\citation{Bifet2007}
\citation{Bifet2007}
\citation{Bifet2007}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Output of the ADWIN algorithm illustrating abrupt concept drift. When the average error changes significantly, ADWIN shrinks the window and triggers model adjustment. Adapted from Bifet and Gavaldà\nonbreakingspace \citep  {Bifet2007}.}}{26}{figure.caption.33}\protected@file@percent }
\newlabel{fig:adwin}{{6}{26}{Output of the ADWIN algorithm illustrating abrupt concept drift. When the average error changes significantly, ADWIN shrinks the window and triggers model adjustment. Adapted from Bifet and Gavaldà~\cite {Bifet2007}}{figure.caption.33}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Explainable AI (XAI) in Test Debugging}{27}{subsection.5.2}\protected@file@percent }
\citation{Ribeiro2016}
\citation{Ribeiro2016}
\citation{Ribeiro2016}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces LIME explanation example. The red cross marks the instance being explained. The background colors represent the black-box model’s decision surface, and the dashed line shows the linear surrogate model used for local interpretation\nonbreakingspace \citep  {Ribeiro2016}.}}{28}{figure.caption.34}\protected@file@percent }
\newlabel{fig:lime}{{7}{28}{LIME explanation example. The red cross marks the instance being explained. The background colors represent the black-box model’s decision surface, and the dashed line shows the linear surrogate model used for local interpretation~\cite {Ribeiro2016}}{figure.caption.34}{}}
\citation{Lundberg2017}
\citation{Lundberg2017}
\citation{Lundberg2017}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparison of SHAP, Shapley sampling, and LIME. SHAP provides more stable and accurate feature importance estimates relative to the true Shapley value\nonbreakingspace \citep  {Lundberg2017}.}}{29}{figure.caption.35}\protected@file@percent }
\newlabel{fig:shap}{{8}{29}{Comparison of SHAP, Shapley sampling, and LIME. SHAP provides more stable and accurate feature importance estimates relative to the true Shapley value~\cite {Lundberg2017}}{figure.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Challenges}{31}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Over-Reliance on Training Data}{31}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Systemic Risks from Data Dependencies}{31}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Impact on Validation Effectiveness}{31}{subsubsection.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.3}Mitigation Strategies}{32}{subsubsection.6.1.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Data Dependency Mitigation Approaches}}{32}{table.caption.36}\protected@file@percent }
\newlabel{tab:mitigation}{{7}{32}{Data Dependency Mitigation Approaches}{table.caption.36}{}}
\citation{Zhou2024}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Ethical and Legal Risks in AI Testing}{33}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Future Directions and Conclusion}{33}{section.7}\protected@file@percent }
\citation{Li2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Conclusion}{34}{subsection.7.1}\protected@file@percent }
\newlabel{subsec:7.1}{{7.1}{34}{Conclusion}{subsection.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Future Directions}{34}{subsection.7.2}\protected@file@percent }
\newlabel{subsec:7.2}{{7.2}{34}{Future Directions}{subsection.7.2}{}}
\bibcite{Kenfack2021}{{1}{}{{}}{{}}}
\bibcite{Zhou2024}{{2}{}{{}}{{}}}
\bibcite{Kenfack2021}{{3}{}{{}}{{}}}
\bibcite{Zhou2024}{{4}{}{{}}{{}}}
\bibcite{Guo2024}{{5}{}{{}}{{}}}
\bibcite{Li2018}{{6}{}{{}}{{}}}
\bibcite{Chen2004}{{7}{}{{}}{{}}}
\bibcite{Chib1995}{{8}{}{{}}{{}}}
\bibcite{selfapr_paper}{{9}{}{{}}{{}}}
\bibcite{genprog}{{10}{}{{}}{{}}}
\bibcite{angelix}{{11}{}{{}}{{}}}
\bibcite{defects4j}{{12}{}{{}}{{}}}
\bibcite{gzoltar}{{13}{}{{}}{{}}}
\bibcite{recoder}{{14}{}{{}}{{}}}
\bibcite{cure}{{15}{}{{}}{{}}}
\bibcite{nopol}{{16}{}{{}}{{}}}
\bibcite{deeprepair}{{17}{}{{}}{{}}}
\bibcite{tbar}{{18}{}{{}}{{}}}
\bibcite{buglab}{{19}{}{{}}{{}}}
\bibcite{rewardrepair}{{20}{}{{}}{{}}}
\bibcite{aprgnn}{{21}{}{{}}{{}}}
\bibcite{jgenprog}{{22}{}{{}}{{}}}
\bibcite{Li2024}{{23}{}{{}}{{}}}
\bibcite{Bifet2007}{{24}{}{{}}{{}}}
\bibcite{Ribeiro2016}{{25}{}{{}}{{}}}
\bibcite{Lundberg2017}{{26}{}{{}}{{}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.185pt}
\newlabel{tocindent2}{10.35pt}
\newlabel{tocindent3}{18.198pt}
\newlabel{tocindent4}{0pt}
\newlabel{tocindent5}{0pt}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {section}{References}{35}{section*.38}\protected@file@percent }
\newlabel{TotPages}{{35}{35}{}{page.35}{}}
\gdef \@abspage@last{35}
